--- 
title:  "Lecture 5: "
editor_options: 
  chunk_output_type: console
---

<br>

This session is based on the paper,

Chen, Y., Xiang, J., Wang, Z., Xiao, Y., Zhang, D., Chen, X., Li, H., Liu, M. and Zhang, Q., 2015.  
**Associations of bone mineral density with lean mass, fat mass, and dietary patterns in postmenopausal Chinese women: a 2-year prospective study.**  
PloS one, 10(9), p.e0137097.  

The paper can be found at https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0137097 and the authors have made their data available by placing two Excel files in the dryad repository at https://datadryad.org/stash/dataset/doi:10.5061%2Fdryad.36k08.  

282 postmenopausal women from Harbin City, China were followed between 2009 and 2011 to study changes in bone mineral density (BMD). Dietary data were collected by food frequency questionnaires.

In this session we will cover,
 
* A simple function
* A basic shiny app      

<br>

<hr style = "border:2px solid #3559A6"> </hr>

<br>

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```

# List columns

A tibble is the tidyverse equivalent of a data frame. Usually, the columns of a tibble are vectors and as such the entries must all be of the same type.

```{r}
tibble( name = c("Jack", "Jill", "Mary", "Jane", "Fred"),
        age  = c(  43,  25,  60,  47,  55),
        smoker = factor( c("No", "No", "Yes", "No", "Yes"))) %>%
  print()   -> testDF
```

`testDF` has a column of characters, a column of doubles and a column of factor levels. Columns with single values are sometimes called `atomic`.

An important alternative is to have a column that is a list rather than a vector. A list can contain any type of object so it is much more flexible.

In the following example, I add the dates when the the individuals visited a clinic. The number of visits varies from 1 to 3 and the dates are stored as strings.
```{r}
tibble( name = c("Jack", "Jill", "Mary", "Jane", "Fred"),
        age  = c(  43,  25,  60,  47,  55),
        smoker = factor( c("No", "No", "Yes", "No", "Yes")),
        visits = list( c("2021-06-02", "2021-09-20"),
                       c("2020-10-16", "2021-02-12", "2021-06-02"),
                       c("2021-04-02", "2021-07-22"),
                       c("2021-06-02"),
                       c("2021-08-02", "2021-11-20") )) %>%
  print()   -> testDF
```

The dates can be extracted from the list using the $ and [[ ]] notations
```{r}
print( testDF$visits[[3]] )
```

or there is a tidyverse function called **pluck()** that does the same job
```{r}
testDF %>%
  pluck("visits", 3) %>%
  print()
```

First, the list call "visits" is selected and from within that list the 3rd item is chosen. `pluck() will dig deeper if we choose; next I take the 2 date from visits[[3]]

```{r}
testDF %>%
  pluck("visits", 3, 2) %>%
  print()
```

<br>

<hr style = "border:2px solid #3559A6"> </hr>

<br>

# Nesting and unnesting

To expand a list column and show its entries it is unexted using the **unnest()** function.

```{r}
testDF %>%
  unnest( visits ) %>%
  print()   -> longTestDF
```

We can recreate a list column using **nest()**

```{r}
longTestDF %>%
  nest( dates = visits ) %>%
  print()
```

Notice that nest() creates a list of tibbles(). I have chosen to call this list column `dates`

In the next example, I create tibbles for smokers and non-smokers. Each tibble contains the subjects name, age and the dates of thier visits.

```{r}
longTestDF %>%
  nest( dfs = c(name, age, visits)) %>%
  print() ->   smokerDF
```

I can look at the tibble for non-smokers using pluck()
```{r}
smokerDF %>%
  pluck("dfs", 1)
```

<br>

<hr style = "border:2px solid #3559A6"> </hr>

<br>

# Repeating a calculation over a list column

In Lecture 4, we saw how to use across() to repeat a calculation over the columns of a tibble. Now we turn to repeating over the rows.

Let's return to testDF and imagine that we want to repeat a calculation on every row 
```{r}
print( testDF)
```

If the calculation only involves `atomic` columns use mutate with a simple formula
```{r}
# approximate age in months
testDF %>%
  mutate( monthAge = 12*age + 6 ) %>%
  print()
```

However, calculating on a list is more complex and requires a function called **map()**. 

map() applies a function to each row of a list column.

For instance, the dates of Jill's visits were,
```{r}
testDF %>%
  pluck( "visits", 2)
```

If we apply the min() function to Jill's dates, we will get the date of the first visit
```{r}
testDF %>%
  pluck( "visits", 2) %>%
  min()
```

So to calculate the date of the first visit for every person, we use map() with the function min() applied to visits
```{r}
testDF %>%
  mutate( firstVisit = map(visits, min)) %>%
  print()
```

Notice that the result, `firstVisit`, is also a list column. 

map() is quite general and it does not know in advance what type of value will be returned. A list can contain anything, so it is the safe choice. 

If you want to turn firstVisit into an atomic vector of characters, unnest it.

```{r}
testDF %>%
  mutate( firstVisit = map(visits, min)) %>%
  unnest( firstVisit ) %>%
  print()
```

In this example, we know that the result will be a string, so we could tell map() what to expect by calling map_chr()
```{r}
testDF %>%
  mutate( firstVisit = map_chr(visits, min)) %>%
  print()
```

Now map creates a character column instead of a list column.

Other special forms of map() include, 
map_lgl() ... result is boolean TRUE/FALSE  
map_dbl() ... result is a double precision real number  
map_int() ... result is an integer  
map_df()  ... result is a data frame or tibble  

<br>

<hr style = "border:2px solid #3559A6"> </hr>

<br>

# Bootstrapping

In Lecture 3, I described a bootstrap analysis of these data
```{r}
tibble( id    = 1:8,
        sex   = c("m", "f", "m", "m", "f", "f", "f", "f"),
        age   = c( 45,  37,  25,  36,  52,  29,  53,  48),
        sbp   = c(135, 130, 120, 115, 155, 140, 145, 135) ) %>%
  mutate( sex = factor(sex, levels = c("m", "f"),
                            labels = c("male", "female"))) %>%
  print() -> sbpDF
```

I used a **loop** to repeatedly take bootstrap samples of the data and each time calculate the median SBP. One problem with loops is that the break up the flow of a pipe. Effectively, they require you to mix for loops from base R with a pipe from the tidyverse; an untidy mix of styles.

Loops can be always be run `inside a pipe` using `list columns` and the `map` functions.  

The **rsample** package has a function for creating bootstrap samples.
```{r}
library(rsample)

set.seed(7283)

sbpDF %>%
  bootstraps( times = 5) %>%
  print()  -> bootDF
```

I have created 5 bootstrap samples stored as a list column called splits together with a row identifier called id.

Take row 3 as an example. sbpDF has 8 rows so the bootstrap sample also has 8 rows, but because the same row from sbpDF can be used more than once, there are 3 rows from sbpDF that were not used in creating that bootstrap sample.

The unused rows are sometimes called `out-of-the-bag` (OOB) and they can be used an an independent check on the bootstrap calculation.

It looks at first sight as if split 3 contains a tibble with 8 rows and a tibble with 3 rows. Were this the case then bootDF would be much larger than sbpDF and if we wanted many bootstrap samples of a large data frame, it could easily become impractical.  

`rsample` avoids the size problem by saving a copy of sbpDF and in bootDF the splits only contain the row numbers, which it saves at `in_id`.

```{r}
bootDF %>%
  pluck("splits", 3, "in_id") 
```

rsample provides functions `analysis()` and `assessment()` for reconstructing the tibbles. Let's again look at row three 
```{r}
bootDF %>%
  pluck("splits", 3) %>%
  analysis()

bootDF %>%
  pluck("splits", 3) %>%
  assessment()
```

Now lets' write a function that takes a split and calculates the median of the analysis dataset
```{r}
# find the median SBP from a single split
# arguments
#    split ... a single split created by rsample
# return
#    median SBP
#
split_median <- function( split) {
  split %>%
    analysis() %>%
    summarise( medSbp = median(sbp)) %>%
    pluck( "medSbp", 1) %>%
    return()
}

# test the function on split 3
bootDF %>%
  pluck("splits", 3) %>%
  split_median()  
```

I know that split_median returns a number so it simplifies the code if I use map_dbl() to reat the calculation over all of the splits
```{r}
bootDF %>%
  mutate( median = map_dbl( splits, split_median)) %>%
  print()
```

Now we can scale up to 1000 bootstrap samples. Once I have the medians for each sample I want to plot them and summarise them. There are two ways to do this

* write an analysis function  
* create an anonymous function with curly brackets and the dot  

```{r}
# Method 1: using a function
# 
# function to 
myAnalysis <- function(thisDF) {
  # histogram of the medians
  thisDF %>%
     ggplot( aes(x=median) ) +
        geom_histogram( bins=40, fill="steelblue" ) -> p
     print(p)
  # summary of the medians
  thisDF %>%
     summarise( m   = mean(median),
                se  = sd(median)) %>%
       return()
}

# Use the function
set.seed(7283)

sbpDF %>%
  # create 1000 bootstrap samples
  bootstraps(1000) %>%
  # find the median of each sample
  mutate( median = map_dbl( splits, split_median)) %>%
  # run my analysis
  myAnalysis()
```

5.45 is the bootstrap standard error of the median. Like any other standard error it tells us how accurately we know the median of the original population of patients. We only have a sample of 8 patients, so not surprisingly, the estimated median is not very accurate.  

Notice that a plot created inside a function will only appear if it is explicitly requested.  

Now the anonymous function method

```{r}
# Method 2: using an anonymous function
# 
set.seed(7283)

sbpDF %>%
  # create 1000 bootstrap samples
  bootstraps(1000) %>%
  # find the median of each sample
  mutate( median = map_dbl( splits, split_median)) %>%
  # anonymous analysis function
    {
    # plot a histogram
     ggplot(., aes(x=median)) +
        geom_histogram( bins=40, fill="steelblue" ) -> p
     print(p)
    # summarise the medians
     summarise(., m   = mean(median),
                  bse = sd(median)) 
    }
```

The second method is more concise, but perhaps a little more difficult to read.

<br>

<hr style = "border:2px solid #3559A6"> </hr>

<br>

# Permutation testing

We might use a t-test to test whether there is evidence that SBP is higher or lower in men compared with women.
```{r}
sbpDF %>%
  t.test( sbp ~ sex, data = .)
```

The test statistic is -2.3906 indicating a lower SBP in men and the p-value is close to conventional significance, but the normality assumption is hard to justify, which makes the test questionable.  

Can we create a non-parametric test that does not rely on normality? One method is to use the statistic from the t-test but to calculate its p-value using permutations of the original data.  

Permutations are the testing equivalent of bootstrapping the standard error.

**rsample** has a function permutations() that creates random splits. Here is an example of one such permutation
```{r}
# seed for reproducibility
set.seed(8299)

# create a single permutation & display it
sbpDF %>%
  permutations( sbp, times=1) %>%
  pluck( "splits", 1) %>%
  analysis() %>%
  print()
```

The 8 patients are kept but their SBPs are randomly permuted.

If there is no SBP difference between men and women (our null hypothesis) then permutation makes no difference to a t-test
```{r}
set.seed(8299)

# t-test on the permutation
sbpDF %>%
  permutations( sbp, times=1) %>%
  pluck( "splits", 1) %>%
  analysis() %>%
  t.test( sbp ~ sex, data = .)
```

The test statistic of 0.29681 indicates a slightly higher SBP in men but we know it is a chance finding, because SBP was randomly allocated.

Repeating the permutations shows what we would get from the t-test under the null of no difference between men and women

```{r}
# find the t-test statistic for a single split
# arguments
#   split .. a single permutation
# returns
#   the t-test staistic
#
tStatistic <- function( split ) {
  analysis(split) %>%
    t.test( sbp ~ sex, data = . ) %>%
    pluck( "statistic" ) %>%
    return()
}

# test the function with 5 permutations
set.seed(8299)
sbpDF %>%
  permutations( sbp, times=5) %>%
  mutate( t = map_dbl( splits, tStatistic)) %>%
  print()
```

As we might expect the test statistics are close to zero when there is no difference between men and women.

Now I scale up and use an anonymous function to plot the distribution of permuted statistics and to find the permuted p-value
```{r}
set.seed(8299)
sbpDF %>%
  permutations( sbp, times=1000) %>%
  mutate( t = map_dbl( splits, tStatistic)) %>%
    {
    ggplot(., aes(x=t)) +
      geom_histogram( bins = 25 , fill = "steelblue") +
      geom_vline( xintercept = -2.3906, colour = "red", size = 2) -> p
    print(p)
    
    summarise( ., p = sum( t <= -2.3906 | t >= 2.3906) / 1000)
    }
```

The real data had a test statistic of -2.3906, which is quite far from zero. Such extreme statistics are rarely generated by chance.

The permutation two-tailed p-value is 0.061; a p-value that does not rely on any distributional assumption.  

<br>

<hr style = "border:2px solid #3559A6"> </hr>

<br>


# Shiny

more widgets and data tables